server:
  extraFlags:
  - web.enable-lifecycle
  - web.enable-remote-write-receiver
  - enable-feature=exemplar-storage
  - enable-feature=otlp-write-receiver
  resources: {}
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 500m
    memory: 512Mi

prometheus-node-exporter:
  hostRootFsMount:
    enabled: false

serverFiles:
  alerting_rules.yml:
    groups:
    - name: Test_Alerts_Work
      rules:
      - alert: Test_Alerts
        expr: up{service="prometheus-demo-kube-state-metrics"} == 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Test {{ $labels.instance }} alert"
          description: "{{ $labels.instance }} of job {{ $labels.job }} has been up for more than 1 minute."

alertmanager:
  enabled: true
  config:
    enabled: true
    global:
      resolve_timeout: 5m

    route:
      receiver: 'slack'
      group_by: ['alertname']
      group_wait: 30s
      group_interval: 1m
      repeat_interval: 1m

    receivers:
    - name: 'slack'
      slack_configs:
      - send_resolved: true
        api_url: 'https://hooks.slack.com/services/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'
        channel: '#herond-alert'
        title: '{{ template "SLACK_MSG_TITLE" . }}'
        text: '{{ template "SLACK_MSG_TEXT" . }}'
        footer: 'Alertmanager'
  templates:
    alertmanager.tmpl: |-
      {{ define "RUNBOOK_SEARCH" }}https://dsmith73.github.io/101-docs/search/?q={{ .CommonLabels.alertname }}{{ end }}

      {{ define "SLACK_MSG_COLOR" }}{{ if eq .Status "firing" }}{{ if eq .CommonLabels.severity "critical" }}danger{{ else if eq .CommonLabels.severity "error" }}danger{{ else if eq .CommonLabels.severity "warning" }}warning{{ else }}#439FE0{{ end }}{{ else}}good{{ end }}{{ end }}

      {{define "SLACK_MSG_TEXT" }}
            <!here> - {{ .CommonAnnotations.description }}
            `View:` :chart_with_upwards_trend:*<{{ (index .Alerts 0).GeneratorURL }}|Prometheus>* or :notebook:*<{{ template "RUNBOOK_SEARCH" . }}|Runbook>*

            *Details:*
            {{ range .CommonLabels.SortedPairs }}â€¢ *{{ .Name }}:* `{{ .Value }}`
          {{ end }}
      {{ end }}

      {{ define "SLACK_TITLE_SUMMARY" -}}
          {{- if .CommonAnnotations.summary -}}
              {{- .CommonAnnotations.summary -}}
          {{- else -}}
              {{- with index .Alerts 0 -}}
                  {{- .Annotations.summary -}}
              {{- end -}}
          {{- end -}}
      {{- end -}}

      {{ define "SLACK_MSG_TITLE" }}
          {{ if eq .Status "resolved" }}
              {{- .Status | toUpper }} : {{ template "SLACK_TITLE_SUMMARY" . }}
          {{ else if eq .Status "firing" }}
              {{ .CommonLabels.severity | toUpper }} : {{ template "SLACK_TITLE_SUMMARY" . }}
          {{ end }}
      {{ end }}
# extraScrapeConfigs: |
#   - job_name: 'otel-collector'
#     scrape_interval: 15s
#     params:
#       module: [http_2xx]
#     static_configs:
#       - targets:
#         - 'opentelemetry-collector:9201'
